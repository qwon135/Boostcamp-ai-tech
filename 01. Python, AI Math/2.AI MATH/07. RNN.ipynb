{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8d87d77",
   "metadata": {},
   "source": [
    "RNN은 모델 자체의 설계는 어렵지 않으나 왜 이렇게 되냐를 아는지가 중요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01eb08b1",
   "metadata": {},
   "source": [
    "### 시퀀스 데이터 이해하기\n",
    "- 소리, 문자열, 주가 등의 데이터를 sequence 데이터로 분류한다.\n",
    "- 시계열(time-series) 데이터는 시간 순서에 따라 나열된 데이터로 시퀀스 데이터에 속한다.\n",
    "- 시퀀스 데이터는 독립동등분포(i.i.d.) 가정을 잘 위배하므로 순서를 바꾸거나 과거 정보에 손실이 발생하면 데이터의 확률 분포도 바뀌게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bc13c9",
   "metadata": {},
   "source": [
    "### 시퀀스 데이터 다루기\n",
    "- 이전 시퀀스 정보를 가지고 앞으로 발생할 데이터의 확률분포를 다루기 위해 조건부확률을 이용\n",
    "- 베이즈 법칙 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68be8589",
   "metadata": {},
   "source": [
    "<img src = \"../../images/ai_15.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849b6e4d",
   "metadata": {},
   "source": [
    "- 시퀀스데이터를 다루기 위해서는 길이가 가변적인 데이터를 다룰 수 있는 모델이 필요하다.\n",
    "- 시퀀스 데이터를 모두 사용할 필요 없이 고정된 $t$개 만큼의 시퀀스만 사용하는 경우 AR($t$)(Autoregressive Model) 자기회귀모델이라고 부른다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb87ea0c",
   "metadata": {},
   "source": [
    "<img src = \"../../images/ai_16.gif\" width = 400> \n",
    "- 또 다른 방법으로 바로 이전 정보를 제외한 나머지 정보들을 $H_t$ 라는 잠재변수로 인코딩해서 활용하는 잠재 AR모델이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbffafc",
   "metadata": {},
   "source": [
    "### RNN 이해하기\n",
    "- 가장 기본적인 RNN모형은 MLP와 유사한 모양이다.\n",
    "- 하지만 과거의 정보를 다룰 수가 없고 현재시점만 다룰 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4663b5b3",
   "metadata": {},
   "source": [
    "<img src = \"../../images/ai_17.gif\" width = 400> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c13aec7",
   "metadata": {},
   "source": [
    "- RNN은 이전 순서의 잠재변수와 현재의 입력을 활용하여 모델링한다.\n",
    "- 잠재변수 $H_t$ 를 복제해서 다음 순서의 잠재변수를 인코딩하는데 사용한다.\n",
    "<img src = \"../../images/ai_18.gif\" width = 400> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f3383f",
   "metadata": {},
   "source": [
    "총 3개의 가중치  \n",
    "- $W_X^{(1)}$ : 입력 데이터에서 잠재변수로 인코딩하게되는 가중치\n",
    "- $W_H^{(1)}$ : 이전 시점의 잠재변수로 정보를 받아 현재 시점의 현재 변수로 인코딩\n",
    "- $W^{(2)}$ : 이렇게 만든 잠재변수를 다시 출력으로 만들어주는 가중치"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faed012",
   "metadata": {},
   "source": [
    "- RNN의 역전파는 잠재변수의 연결그래프에 따라 순차적으로 계산한다. ($x_1$ ~ $x_t$ 까지 흐른다음에 마지막서 다시 거꾸로 흐른다) 이를 Backpropagation Through Time, BPTT라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a33e420",
   "metadata": {},
   "source": [
    "### BPTT\n",
    "- BPTT를 이용해 RNN의 가중치 행렬의 미분을 계산해보면 미분의 곱으로 이루어진 항이 계산된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bf63d3",
   "metadata": {},
   "source": [
    "<img src = \"../../images/ai_19.gif\" width = 700> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd28bf3",
   "metadata": {},
   "source": [
    "### 기울기 소실의 해결책\n",
    "- 과거의 정보 소실\n",
    "- 시퀀스 길이가 길어지는 경우 BPTT를 통한 역전파 알고리즘의 계산이 불안정해지므로 길이를 끊는것이 필요하다. 이를 truncated BPTT라고 한다.(완벽한 해결책 X)\n",
    "- 이러한 문제들 때문에 Vanilla RNN은 길이가 긴 시퀀스를 처리하는데 문제가 있다. 이를 위해 등장한 RNN 네트워크가 LSTM과 GRU이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c4b29d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
