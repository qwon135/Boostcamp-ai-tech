{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b43d3c2a",
   "metadata": {},
   "source": [
    "#  AutoGrad & Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95044ed7",
   "metadata": {},
   "source": [
    "논문 구현 : 수 많은 반복의 연속  \n",
    "Layer = Block \n",
    "Layer를 쌓는것(블록의 연속)을 다시 Layer에 넣기도함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb757909",
   "metadata": {},
   "source": [
    "### torch.nn.Module\n",
    "- 딥러닝을 구성하는 Layer의 base class(Auto Grad)\n",
    "- 4가지를 정함 : Input, Output, Forward, Backward(Weights)\n",
    "- 학습의 대상이 되는 parameter(tensor) 정의"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b272df",
   "metadata": {},
   "source": [
    "### nn.Parameter\n",
    "- Tensor 객체의 상속 객체\n",
    "- nn.Module 내에서 __attribute__ 가 될 때는 required_grad=True(Auto Grad)로 지정되어 학습 대상이 되는 Tensor\n",
    "- 직접 지정할 일은 잘 없다 : 대부분의 layer에는 weights 값들이 지정되어 잇다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86e6e05",
   "metadata": {},
   "source": [
    "### Backward\n",
    "- Layer에 있는 Parameter 들의 미분을 수행\n",
    "- Forward의 결과값(model의 output=예측치)과 실제값간의 loss에 대해 미분\n",
    "- 해당 값으로 Parameter 업데이트\n",
    "- 총 4단계\n",
    " 1. optimizer.zero_grad() \n",
    " 2. loss = criterion(outputs, labels)\n",
    " 3. loss.backward()\n",
    " 4. optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b985cd",
   "metadata": {},
   "source": [
    "### Backward from the scratch\n",
    "- 실제 backward는 Module 단계에서 직접 지정가능(하지만 할필요가 x)\n",
    "- Module에서 backward와 optimizer 오버라이딩\n",
    "- 사용자가 직접 미분 수식을 써야하는 부담감  \n",
    "    $\\rightarrow$ 쓸일은 없으나 순서는 이해할 필요 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa520d9",
   "metadata": {},
   "source": [
    "# PyTorch Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90e54f1",
   "metadata": {},
   "source": [
    "- 모델에 데이터를 먹이는 법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2799df",
   "metadata": {},
   "source": [
    "<img src = \"../images/ai_32.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577dafcd",
   "metadata": {},
   "source": [
    "1. Data가 있는 폴더가 있다.\n",
    "2. Data set class에서 를 어떻게 시작(init)할건지 길이가 얼만지(len) 어떻게 불러올것인지(getitem > __map-style__ 중요)\n",
    "3. transforms에서 data 변형(tensor로)\n",
    "4. DataLoader : 데이터를 묶어서 model에 feeding해줌\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f502e635",
   "metadata": {},
   "source": [
    "### Data set 클래스\n",
    "- 데이터 입력 형태를 정의하는 클래스\n",
    "- 데이터를 입력하는 방식의 표준화\n",
    "- Image, Text, Audio등에 따른 입력 정의 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e049d743",
   "metadata": {},
   "source": [
    "### Dataset 클래스 생성시 유의점\n",
    "- 데이터 형태에 따라 각 함수를 다르게 정의함\n",
    "- 모든 것을 데이터 생성 시점에 처리할 필요는 없음 : image의 Tensor 변화는 학습에 필요한 시점에 변환\n",
    "- Dataset에 대한 표준화된 처리방법 제공 필요 \n",
    "- 최근엔 HuggingFace등 표준화된 라이브러리 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d24c48cf",
   "metadata": {},
   "source": [
    "### DataLoader 클래스\n",
    "- Data의 Batch를 생성해주는 클래스\n",
    "- 학습직전(GPU feed전) 데이터의 변환을 책임\n",
    "- Tensor로 변환 + Batch 처리가 메인 업무\n",
    "- 병렬적인 데이터 전처리 코드의 고민 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71d7e28",
   "metadata": {},
   "source": [
    "### Casestudy\n",
    "- 데이터 다운로드 부터 loader까지 구현해보기\n",
    "- NotMNIST 데이터의 다운로드 자동화 도전|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d29ce264",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skimage'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3b/rtm0n0l56yd2mbcz2vh1106r0000gn/T/ipykernel_24678/2944068721.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'skimage'"
     ]
    }
   ],
   "source": [
    "from torchvision.datasets import VisionDataset\n",
    "from typing import Any, Callable, Dict, List, Optional, Tuple\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import requests\n",
    "\n",
    "from skimage import io, transform\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78664bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tarfile\n",
    "\n",
    "    \n",
    "class NotMNIST(VisionDataset):\n",
    "    resource_url = 'http://yaroslavvb.com/upload/notMNIST/notMNIST_large.tar.gz'\n",
    "    \n",
    "    def __init__(\n",
    "            self,\n",
    "            root: str,\n",
    "            train: bool = True,\n",
    "            transform: Optional[Callable] = None,\n",
    "            target_transform: Optional[Callable] = None,\n",
    "            download: bool = False,\n",
    "    ) -> None:\n",
    "        super(NotMNIST, self).__init__(root, transform=transform,\n",
    "                                    target_transform=target_transform)\n",
    "\n",
    "        if not self._check_exists() or download:\n",
    "            self.download()\n",
    "            \n",
    "        self.data, self.targets = self._load_data()\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_name = self.data[index]\n",
    "        image = io.imread(image_name)\n",
    "        label = self.targets[index]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "    def _load_data(self):\n",
    "        filepath = self.image_folder\n",
    "        data = []\n",
    "        targets = []\n",
    "        \n",
    "        for target in os.listdir(filepath):\n",
    "            filenames = [os.path.abspath(\n",
    "                os.path.join(filepath, target, x)) for x in os.listdir(\n",
    "                os.path.join(filepath, target))]\n",
    "            \n",
    "            targets.extend([target] * len(filenames))\n",
    "            data.extend(filenames)\n",
    "        return data, targets\n",
    "\n",
    "    @property\n",
    "    def raw_folder(self) -> str:\n",
    "        return os.path.join(self.root, self.__class__.__name__, 'raw')\n",
    "\n",
    "    @property\n",
    "    def image_folder(self) -> str:\n",
    "        return os.path.join(self.root, 'notMNIST_large')\n",
    "\n",
    "\n",
    "    def download(self) -> None:\n",
    "        os.makedirs(self.raw_folder, exist_ok=True)\n",
    "        fname = self.resource_url.split(\"/\")[-1]\n",
    "        chunk_size = 1024\n",
    "        \n",
    "        filesize = int(requests.head(self.resource_url).headers[\"Content-Length\"])\n",
    "        \n",
    "        with requests.get(self.resource_url, stream=True) as r, open(\n",
    "            os.path.join(self.raw_folder, fname), \"wb\") as f, tqdm(\n",
    "            unit=\"B\",  # unit string to be displayed.\n",
    "            unit_scale=True,  # let tqdm to determine the scale in kilo, mega..etc.\n",
    "            unit_divisor=1024,  # is used when unit_scale is true\n",
    "            total=filesize,  # the total iteration.\n",
    "            file=sys.stdout,  # default goes to stderr, this is the display on console.\n",
    "            desc=fname  # prefix to be displayed on progress bar.\n",
    "        ) as progress:\n",
    "            for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "                # download the file chunk by chunk\n",
    "                datasize = f.write(chunk)\n",
    "                # on each chunk update the progress bar.\n",
    "                progress.update(datasize)\n",
    "        \n",
    "        self._extract_file(os.path.join(self.raw_folder, fname), target_path=self.root)\n",
    "        \n",
    "    def _extract_file(self, fname, target_path) -> None:\n",
    "        if fname.endswith(\"tar.gz\"):\n",
    "            tag = \"r:gz\"\n",
    "        elif fname.endswith(\"tar\"):\n",
    "            tag = \"r:\"\n",
    "        tar = tarfile.open(fname, tag)\n",
    "        tar.extractall(path=target_path)\n",
    "        tar.close()\n",
    "    \n",
    "    def _check_exists(self) -> bool:\n",
    "        return os.path.exists(self.raw_folder)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001e22a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NotMNIST(\"data\", download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880b05fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "\n",
    "for i in range(8):\n",
    "    sample = dataset[i]\n",
    "\n",
    "    ax = plt.subplot(1, 4, i + 1)\n",
    "    plt.tight_layout()\n",
    "    ax.set_title('Sample #{}'.format(i))\n",
    "    ax.axis('off')\n",
    "    plt.imshow(sample[0])\n",
    "\n",
    "    if i == 3:\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9053af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "\n",
    "data_transform = transforms.Compose([\n",
    "        transforms.RandomSizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "dataset = NotMNIST(\"data\", download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f19fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_loader = torch.utils.data.DataLoader(dataset,\n",
    "                                             batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "109e3433",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, train_labels = next(iter(dataset_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6ea244",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e941d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09c0e6b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3b/rtm0n0l56yd2mbcz2vh1106r0000gn/T/ipykernel_24678/2795388710.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_features' is not defined"
     ]
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e50556d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
