{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b580ec16",
   "metadata": {},
   "source": [
    "What I cannot create, I do not understand. 내가 만들어낼 수 없다면, 난 그것을 이해하지 못한 것이다\n",
    "\n",
    "<center>-리처드 파인만-</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5cdd54",
   "metadata": {},
   "source": [
    "## Generative Models\n",
    "\n",
    "- **Generation** : $x_{new} \\text{~ } p(x),x_{new}$무언가를 생성하지만 Generative Model은 단순히 무언가를 생성하는 것만이 아니다. sampling\n",
    "\n",
    "\n",
    "- **Density estimation** : 즉, 해당 이미지가 강아지 같은 것인지 를 판단할수 있는지에 대한 분류의 개념도포함한다. (explicit models라고 한다.) anomaly detection\n",
    "\n",
    "\n",
    "- **Unsupervised representation learning** : 특성을 파악(꼬리가 있는지, 다리가 있는지) feature learning 이라고 한다\n",
    "\n",
    "\n",
    "- 생성하는 것만아닌 explicit도 가능하다!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827c84eb",
   "metadata": {},
   "source": [
    "### Basic Discrete Distributions(확률 기본)\n",
    "\n",
    "Generative Models를 이해하려면 확률에 대한 이론이 필요하다\n",
    "\n",
    "**Bernoulli distribution** : 0 또는 1, Heads or Tails\n",
    "- $D$ = {Heads, Tails}\n",
    "\n",
    "\n",
    "- Specify $P(X = \\text{Heads} = p.\\text{Then}P(X = \\text{Tails}) = 1 - p$ : 1일 확률이 p면 0이 나올 확률은 1-p\n",
    "\n",
    "\n",
    "- Write : $X$ ~ Ber($p$)\n",
    "\n",
    "**Categorical distribution** : m개의 주사위를 던짐, m-1개의 parameter필요\n",
    "- $D = {1,...,m}$\n",
    "- Specify $P(Y = i) = p_i, \\text{such that} \\displaystyle\\sum^m_{i=1} p_i = 1$\n",
    "- write : $Y$ ~ Cat($p_1,...,p_m$)\n",
    "\n",
    "\n",
    "#### 예시\n",
    "\n",
    "1. RGB는 256 x 256 x 256으로 이루어져 있다.  \n",
    "    $\\rightarrow$이를 표현하려면 256x256x256 - 1개의 parameters필요\n",
    "\n",
    "\n",
    "2. $X_1 ...X_n$ 개의 binary pixels가 있으면  \n",
    "    $\\rightarrow$$2^n$ 개의 경우의 수가 있고 2n - 1개의 parameters가 필요하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2345b3de",
   "metadata": {},
   "source": [
    "### Structure Through Independence\n",
    "- What if $X_1,...,X_n$ are independent, then\n",
    "$$p(x,1...,x_n) = P(x_1)p(x_2)\\dots p(x_n)$$\n",
    "\n",
    "\n",
    "- How many possible states?\n",
    "$$2^n$$\n",
    "\n",
    "\n",
    "- How many parameters to specify$p(x_1,...,x_n)$?\n",
    "$$n$$\n",
    "\n",
    "\n",
    "- $2^n$ entries can be described by just $n$ numbers! But this independence assumption is too strong to model useful distribusions\n",
    "\n",
    "\n",
    "- 기계학습에서는 parameters가 많을 수록 학습이 어렵다. \n",
    "\n",
    "\n",
    "- 그러므로 모든 사용하지 않고 서로 independent 하다고 가정(말이 안되지만)하면 2n 개에서 n 개로 parameters가 줄어든다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93121bc8",
   "metadata": {},
   "source": [
    "### Conditional Independence\n",
    "이 적당한 값을 찾기 위해 3가지 rule이 있다\n",
    "\n",
    "- **Chain rule** \n",
    "    - 어떤 가정도 하지 않고 아무것도 바뀐 것이 없다\n",
    "    - Fully dependent model과 같은 parameter를 가진다.\n",
    "    - $1+2+2^2+\\dots+2^{n-1}=2^n-1$\n",
    "    - $2^n-1$개의 parameter를 가짐\n",
    "\n",
    "$$p(x_1,...x_n)=p(x_1)p(x_2|x_1)p(x_3|x_1,x_2)\\dots p(x_n|x_1,\\dots,x_{n-1})$$\n",
    "\n",
    "\n",
    "\n",
    "- **Bayes' rule**\n",
    "\n",
    "$$p(x|y)=\\frac{p(x,y)}{p(y)}=\\frac{p(y|x)p(x)}{p(y)}$$\n",
    "\n",
    "\n",
    "- **Conditional Independence**\n",
    "    - suppose $X_{i+1} \\perp X_!,\\dots,X_{i-1}|X_i$(    - Markov assumption), then\n",
    "        - $p(x_1,\\dots,x_n) = p(x_1)p(x_2|x_1)\\dots p(x_n|x_{n-1})$\n",
    "    - parameters 는 $2n-1$개이다.\n",
    "    - Markov assumption으로 parameter를 줄일수 있따\n",
    "    - 이를 Auto-regressive Model이라 한다.\n",
    "$$\\text{if } x \\perp\t y | z, \\text{then } p(x|y,z) = p(x|z)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b390bd",
   "metadata": {},
   "source": [
    "## Auto-regressive Model\n",
    "\n",
    "- 28 x 28 binary pixels가 있다고 하면\n",
    "\n",
    "\n",
    "- 목표는 $p(x) = p(x_1,...,x_{784}$ over $x\\in \\{0,1\\}^{784}$\n",
    "\n",
    "\n",
    "- $p(x)$를 어떻게 parametrize(표현?) 할까\n",
    "    - chain rule 사용        \n",
    "    - $p(x_{1:784}) = p(x_1)p(x_2|x_1)p(x_3|x_{1:2})\\dots$     \n",
    "    - 이를 autogressive model 이라고 한다\n",
    "    -  image 는 순서가 지그지그 일수도 행, 열일 수도 있으므로 어떤 식으로 ordering을 할지에 따라 결과가 바뀐다.\n",
    "    \n",
    "- 1~n 까지 dependence한 가정도 n-1 ~ n까지의 가정도 모두 Auto-regressive Model이다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfdeb32",
   "metadata": {},
   "source": [
    "### NADE : Neural Autoregressive Density Estimator\n",
    "\n",
    "- i번째 pixel을 1~ (i-1) 까지 dependent하게 하는 것\n",
    "- i번째 pixel에 대해\n",
    "\n",
    "$$ p(x_i|x_{1:i-1})=\\sigma(\\alpha_ih_i+b_i)\\text{ where }h_i = \\sigma(W_{<i}x_{1:i-1}+c)$$\n",
    "\n",
    "- NADE는 explicit model 이다.\n",
    "- 즉 generation만 하는게 아닌 Chain-rule을 통해 쪼개면 모든 pixel에 대한 확률을 알 수 있다. \n",
    "    - $\\{x_1,x_2,\\dots,x_{784}\\}$에 대해\n",
    "    - $p(x_{1:784}) = p(x_1)p(x_2|x_1)\\dots p(x_784|x_{1:783})\\dots$ 이므로\n",
    "    - $p(x_i|x_{1:i-1})$을 알면 확률을 알 수 있다.\n",
    "\n",
    "\n",
    "- 예시의 binary가 아닌 continous random variables이면, mixture of Gaussian을 사용할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7438d35",
   "metadata": {},
   "source": [
    "### Pixel RNN\n",
    "- RNNs to define auto-regressive model\n",
    "\n",
    "\n",
    "- $n \\times n$ RGM image가 있다고 할시\n",
    "\n",
    "    $$ p(x)={\\prod}^{n^2}_{i=1}p(x_{i,R}|x_{<i})p(x_{i,G}|x_{<i},x_{i,R})p(x_{i,B}|x_{<i},x_{i,R},x_{i,G})$$\n",
    "\n",
    "- pixel에 대한 RNN을 만듬.\n",
    "\n",
    "\n",
    "- ordering에 따라 Row LSTM(위쪽 정보 활용), Diagonal BiLSTM(이전 정보들을 다 활용) 으로 나뉜다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59661041",
   "metadata": {},
   "source": [
    "---\n",
    "## Latent Variable Models\n",
    "\n",
    "D.Kingma, \"Variational Inference and Deep Learning : A New Synthesis, Ph.D.Thesis\" 논문을 꼭 읽어보자"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67aec75",
   "metadata": {},
   "source": [
    "#### Question?  \n",
    "- Is an **autoencoder** a generative model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5be106",
   "metadata": {},
   "source": [
    "### Variational Auto-encoder\n",
    "\n",
    "- Variational inference(VI)\n",
    "    - posterior distribution을 찾는 것이 목표\n",
    "    - posterior distribution(사후확률) \n",
    "        - $P_\\theta(z|x)$\n",
    "        \n",
    "    - Variational distribution : 사후확률은 근사하기 힘들 때 구함\n",
    "        - $q_\\phi(z|x)$\n",
    "        \n",
    "    -  posterior distribution과 Variational distribution의 격차를 줄이기 위해선 loss functions인 KL divergence를 줄여야 한다.\n",
    "    \n",
    "    \n",
    "- **How?**\n",
    "    - posterior error를 모르는 상태에서 Variational distributiont을 잡을순 없다. \n",
    "    - 이를 가능하게 해주는 것이 ELBO (trick)이다\n",
    "    - ELBO를 키우면서 KL divergence를 구할 수 있다\n",
    "    - $\\log p_\\theta(D)=\\mathbb E_{q_{\\phi}(z|x)}[\\log \\frac{p_{\\theta}(x,z)}{q_{\\phi}(z|x)}] + D_{KL}(q_{\\phi}(z|x)||p_\\theta(z|x))$  \n",
    "    - ELBO : $ \\mathbb E_{q_{\\phi}(z|x)}[\\log \\frac{p_{\\theta}(x,z)}{q_{\\phi}(z|x)}]$를 키운다.\n",
    "    - 위 식은 Reconstruction Term과 Prior Fitting Term로 나눈다\n",
    "    \n",
    "    \n",
    "- Key limitation \n",
    "    - It is an intractable model \n",
    "    - The prior fitting term must be differentiable, hence it is hard to use diverse latent prior distributions.\n",
    "    - In most cases, we use an isotropic Gaussian."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da7e4eb",
   "metadata": {},
   "source": [
    "Variational Auto-encoder의 가장 큰 단점은 prior에서 KL divergence를 사용해 Gaussian 사용이 강제됨, 만약 Gaussian을 사용하지 않으려면\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a96a669",
   "metadata": {},
   "source": [
    "### Adversarial Auto-encoder\n",
    "- It allows us to use any arbitrary latent distributions that we can sample."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c302e76",
   "metadata": {},
   "source": [
    "## Generative Adversarial Network\n",
    "`I. Goodfellow et al., \"Generative Adversarial Networks\", NIPS, 2014`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7070eadd",
   "metadata": {},
   "source": [
    "### GAN\n",
    "- 위조 지폐범과 $\\leftrightarrow$ 위조지폐 검거 경찰의 비유\n",
    "- 지폐위조를 하고 검증을 하는 과정에서 서로의 실력이 올라감\n",
    "\n",
    "\n",
    "$$\\displaystyle\\min_G\\displaystyle\\max_DV(D,G)=\\mathbb E_{x\\text~p_{data(x)}}[\\log D(x)]+\\mathbb E_{z\\text~p_z(z)}[\\log(1-D(G(z)))]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf9d872",
   "metadata": {},
   "source": [
    "### GAN vs VAE\n",
    "- GAN은 true/false 학습 후 Real/Fake를 다시 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf40510",
   "metadata": {},
   "source": [
    "### GAN Objective\n",
    "- A two player minimax game between generator and discriminator.\n",
    "- 한명은 높이고 싶어하고, 한명은 낮추고싶어하는 게임에 비유\n",
    "\n",
    "- For discriminator(판별자):\n",
    "$$\\displaystyle\\max_DV(G,D)=\\mathbb E_{x\\text~p_{data}}[\\log D(x)]+\\mathbb E_{x\\text~p_G}[\\log(1-D(x)]$$\n",
    "\n",
    "- where the optimal discriminator is\n",
    "$$D^*_G(x) = \\frac{p_{data(x)}}{p_{data(x)}+p_{G(x)}}$$\n",
    "\n",
    "- For generator:\n",
    "$$\\displaystyle\\min_GV(G,D)=\\mathbb E_{x\\text~p_{data}}[\\log D(x)]+\\mathbb E_{x\\text~p_G}[\\log(1-D(x)]$$\n",
    "\n",
    "- Plugging in the optimal discriminator, we get\n",
    "$$2D_{JSD}[p_{data},p_G]-\\log4$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbaf55c",
   "metadata": {},
   "source": [
    "### GAN의 종류\n",
    "- DCGAN : image domain을 사용한 gan\n",
    "- info-GAN : 특정 vector에 집중하게 해줌\n",
    "- Text2Image : 문장이 주면 image를 반환\n",
    "- Puzzle-GAN\n",
    "-**Cycle GAN** : 꼭 알아야한다. Cycle-consistency loss, 말 사진만 주어도 얼룩말 반환\n",
    "- Star-GAN : 사람 image에 표정, 나이, 성별등을 바꿈\n",
    "- Progressive-GAN : 고차원 image를 다룬다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87e1b5ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.9041, 2.1452, 2.0041, 1.9685])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "w = torch.tensor([2.,4.,6.,8.])\n",
    "nn.init.normal_(w,2,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db901a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
