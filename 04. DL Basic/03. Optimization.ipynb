{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a86d9c6",
   "metadata": {},
   "source": [
    "Gradient Descent\n",
    "- First-order iterative optimizatino algorithm for finding a local minimum of a differentiable function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348f0564",
   "metadata": {},
   "source": [
    "## Important Concepts in Optimization(용어)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bd09b218",
   "metadata": {},
   "source": [
    "### Generalization : 일반화\n",
    "\n",
    "\n",
    "- 모델의 일반화 성능을 높이는 것이 목표\n",
    "- 일반화 성능은 Training error $\\leftrightarrow$ Test error의 gap 이다"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5c43f116",
   "metadata": {},
   "source": [
    "### Underfitting vs Overfitting\n",
    "\n",
    "- Overfitting : 학습데이터에 잘 동작하지만 테스트데이터에 동작하지 않는 것\n",
    "- Underfitting : Net이 너무 간단해 학습데이터도 못맞춤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a02139",
   "metadata": {},
   "source": [
    "### Cross-validation : 교차 검증\n",
    "- Cross-validation is a model validation technique for assessing how the model will generalize to an independent(test) data set\n",
    "\n",
    "\n",
    "- Cross-validation은 독립적인 데이터들에대해 모델의 일반화 성능을 검증하는 기술\n",
    "\n",
    "\n",
    "- 전체 Data set을 k개로 분할하고 k-1개로 Train 시키고 남은 1개로 Test를 한다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cd1564",
   "metadata": {},
   "source": [
    "### Bias and Variance\n",
    "\n",
    "- Variance : 출력이 얼마나 일관적인가\n",
    "    - Low Variance : 대부분 간단한 모델\n",
    "    - High Variance : overfitting 된 가능성이 크다\n",
    "- Bias : True target 평균\n",
    "    - Low Bias : 평균적으로 True target 접근\n",
    "    - High Bias : 평균적으로 True target에 멀다\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4ff77f46",
   "metadata": {},
   "source": [
    "### Bias and Variance Trade off\n",
    "$$\\text{Given}\\ D = \\{(x_i, y_i)\\}^N_{i=1},\\  \\text{where}\\ t = f(x) + \\epsilon \\text{  and } \\ \\epsilon ~ N(0, \\delta ^2)$$\n",
    "\n",
    "We can derive that what we are minimizing(cost) can be decomposed into three diffrent parts : bias$^2$, variance and noise\n",
    "\n",
    "-> cost는 bias, variance, noise로 이뤄져있어 모두 줄이는 것은 힘들다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f8c656",
   "metadata": {},
   "source": [
    "### Bootstrapping\n",
    "- Boostrapping is any test or metric that uses random sampling with replacement\n",
    "- 학습 데이터가 고정되어 있을 때 무작위 샘플링을 하여 여러 모델을 만들겠다\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f679a64",
   "metadata": {},
   "source": [
    "## Ensemble : Bagging vs Boosting\n",
    "- 하나의 모델모단 여러 개의 모델을 학습시켜 그 모델들의 예측 결과들을 이용한다면 더 정확한 예측값을 구할 수 있다.\n",
    "\n",
    "\n",
    "- 앙상블 학습은 여러 개의 결정 트리(Decision Tree)를 결합하여 하나의 결정 트리보다 더 좋은 성능을 내는 머신러닝 기법\n",
    "\n",
    "\n",
    "- 핵심은 여러 개의 약 분류기 (Weak Classifier)를 결합하여 강 분류기(Strong Classifier)를 만드는 것이다.\n",
    "\n",
    "\n",
    "- 앙상블 학습법에는 Bagging, Boosting 라는 두가지 방법이 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc788811",
   "metadata": {},
   "source": [
    "### Bagging(Boostrapping aggregating)\n",
    "\n",
    "\n",
    "<img src = \"../images/Bagging.png\" width = 500>\n",
    "\n",
    "- Data에서 sample을 여러 번 뽑아(Bootstrap) 각 모델을 학습시키고 그 결과물을 집계(Aggregration)한다.\n",
    "\n",
    "\n",
    "- 집계는 투표 방식(Votinig)으로 하며 평균으로 집계한다. 즉 결정 트리 모델이 예측한 값에 평균을 취해 최종 Bagging Model의 예측값을 결정한다\n",
    "    \n",
    "    \n",
    "- 대표적인 모델 : 랜덤 포레스트(Random Forest)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd13ca0",
   "metadata": {},
   "source": [
    "### Boosting\n",
    "\n",
    "- Boosting은 Weight를 활용하여 약 분류기 (Weak Classifier)를 강 분류기(Strong Classifier)로 만든다.\n",
    "\n",
    "- Bagging이 여러 개의 독립적인 데이터로 결과를 도출했다면 Boosting은  모델 간 팀워크가 이루어진다.\n",
    "\n",
    "\n",
    "<img src = \"../images/Boosting.png\" width = 500>\n",
    "\n",
    "\n",
    "- +와 -로 구성된 데이터셋을 분류하는 모델\n",
    "\n",
    "\n",
    "- D1 : 분류하는 선을 보면 위쪽의 +, 아래쪽의 - 2개가 잘못 분류되었다. 잘못 분류되었으면 가중치를 높여주고, 잘 분류되면 가중치를 낮춘다.\n",
    "\n",
    "\n",
    "- D2 : 잘못 분류된 -가 3개있다. D1에서 잘 분류된 데이터의 크기가 작아졌고(가중치가 낮아졌고) 잘못 분류된 데이터의 크기가 커졌다.(가중치가 커졌습니다.) 그 이유는 잘 못 분류된 데이터를 더 집중해 분류하기 위함이다.\n",
    "\n",
    "\n",
    "- D3 : - 3개의 가중치가 커졌다. D1에서 잘못 분류한 +와 -는 D2에서는 잘 분류가 되어 때문에 D3에서는 가중치가 다시 작아졌다.\n",
    "\n",
    "\n",
    "- D1, D2, D3의 Classifier를 합쳐 최종 Strong Classifier를 구할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f321c83f",
   "metadata": {},
   "source": [
    "### 결론 : Boosting vs Bagging\n",
    "\n",
    "<img src = \"../images/bvsb.png\" width = 500>\n",
    "\n",
    "\n",
    "- Bagging이 병렬로 학습하는 반면 \n",
    "\n",
    "\n",
    "- Boosting은 순차적(Sequential)으로 한다. 학습 결과에 따라 가중치를 부여하고 부여된 가중치가 다음 모델의 결과 예측에 영향을 준다.\n",
    "\n",
    "\n",
    "- 오답에 대해서는 높은 가중치를 부여하므로 오답에 더 집중할 수 있다.\n",
    "\n",
    "\n",
    "- 그러므로 Boosting은 Bagging 비해 error가 적다. 즉, 성능이 좋다. \n",
    "\n",
    "\n",
    "- 하지만 속도가 느리고 overfitting이 될 가능성이 있다. \n",
    "\n",
    "\n",
    "- 성능과 overfitting 사이에서 적절한 선택이 중요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92ae1e8",
   "metadata": {},
   "source": [
    "___\n",
    "## Gradient Descent Methods\n",
    "- Stochastic gradient descent\n",
    "    - Update with the gradient computed from a **single sample**\n",
    "\n",
    "\n",
    "- Mini-batch gradient descent\n",
    "    - Update with the gradient computed from a **subset of data**\n",
    "    \n",
    "    \n",
    "- Batch gradient descent\n",
    "    - Update with the gradient computed from the **whole data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e45546",
   "metadata": {},
   "source": [
    "### Batch-size Matters\n",
    "\n",
    "<img src = \"../images/ai_36.png\" width = 500>\n",
    "\n",
    "\n",
    "- Large batch methods $\\rightarrow$ Sharp Minimum에 도달 \n",
    "    - Sharp Minimum은 Testing 에 대하여 잘 적용되지 않는다.\n",
    "\n",
    "\n",
    "- Small batch methods를 $\\rightarrow$  Flat Minimum에 도달\n",
    "    - Flat Minimum은 Training Data에서 멀어지지만 Testing Function에서도 적당히 낮은 값이 나온다. (즉 Training과 Testing의 오차가 적다.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1249a6",
   "metadata": {},
   "source": [
    "## Gradient Descent \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f34e06",
   "metadata": {},
   "source": [
    "### (Stochastic) gradient descent \n",
    "\n",
    "$$ W_{t+1} \\leftarrow W_t - \\eta g_t $$\n",
    "\n",
    "\n",
    "가중치 $W$에 $\\eta g_t$를 빼준다. 하지만 적절한 Learning rate를 찾는 것이 어렵다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb0f9f9",
   "metadata": {},
   "source": [
    "### Momentum\n",
    "\n",
    "$$ a_{t+1} \\leftarrow \\beta a_t + g_t$$   \n",
    "$$ W_{t+1} \\leftarrow W_t - \\eta a_{t+1} $$\n",
    "\n",
    "- 한번 gradient의 방향성이 정해지면 다음 batch에서 방향성이 바껴도 그 방향성을 유지한다.\n",
    "\n",
    "- gradient가 일정하지 않아도 어느정도 학습이 잘된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9838a6",
   "metadata": {},
   "source": [
    "### Nesterov Accelerated Gradient\n",
    "\n",
    "$$ a_{t+1} \\leftarrow \\beta a_t + \\nabla L(W_t - \\eta Ba_t)$$   \n",
    "$$ W_{t+1} \\leftarrow W_t - \\eta a_{t+1} $$\n",
    "\n",
    "- momentum과 비슷하지만 방향성을 바로 바꾸는 것이 아님\n",
    "\n",
    "- momentum에 의해서 움직인 상태에서의 기울기 상태를 계산하여 이동을 한다.\n",
    "\n",
    "- momentum과 달리 local minimum에 빠져도 나올 수 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81499acb",
   "metadata": {},
   "source": [
    "### Adagrad \n",
    "\n",
    "$$ W_{t+1} = W_t - \\frac{\\eta}{\\sqrt{G_t + \\epsilon}}g_t $$\n",
    "\n",
    "\n",
    "\n",
    "- eta가 너무 작으면 학습 시간이 너무 길고, 너무 크면 발산해서 학습이 제대로 이루어지지 않는다. AdaGrad 는 learning rate decay 를 통해 이를 해결한다.\n",
    "\n",
    "\n",
    "- $G$에 변화한 parameter를 모두 담아 square해준 후 분모에 둬서 많이 변한 parameter는 많이 변화 시키고 적게 변화하면 적게 변화 시킨다. (learning rate decay)\n",
    "\n",
    "\n",
    "\n",
    "- 하지만 $G$가 무한대로 가면 $w$가 update가 잘 되지 않는다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "627a6e44",
   "metadata": {},
   "source": [
    "### Adadelta \n",
    "\n",
    "\n",
    "\n",
    "$$ \\text{EMA of gradient squares : } G_t = \\gamma G_{t-1} + (1 - \\gamma)g^2_t $$\n",
    "\n",
    "\n",
    "$$ \\text{EMA of difference squares : }W_{t+1} = W_t - \\frac{\\sqrt{H_{t-1} + \\epsilon}}{\\sqrt{G_t + \\epsilon}}g_t $$\n",
    "\n",
    "\n",
    "$$ H_t = \\gamma H_{t-1} + (1-\\gamma)(\\Delta W_t)^2 $$\n",
    "\n",
    "\n",
    "- Adagrad의 단점인 $G_t$가 계속 변화는 것을 방지. learning late이 없어 많이 사용되지는 않는다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ab6238",
   "metadata": {},
   "source": [
    "### RMSprop \n",
    "\n",
    "$$\\text{EMA of gradient squares : } G_t = \\gamma G_{t-1} + (1 - \\gamma)g^2_t $$\n",
    "\n",
    "\n",
    "$$ W_{t+1} = W_t - \\frac{\\eta}{\\sqrt{G_t + \\epsilon}}g_t $$\n",
    "\n",
    "\n",
    "- Geoff Hinton 라는 사람이 해보니 잘되어서 사용. step size를 집어넣는다.\n",
    "\n",
    "\n",
    "- RMSProp 은 기울기를 단순 누적하지 않고 지수 가중 이동 평균(Exponentially weighted moving average)을 사용하여 최신 기울기들이 더 크게 반영되도록 하였다.\n",
    "\n",
    "\n",
    "- 지수 가중 이동 평균은 쉽게 말해 \"오래된 데이터일수록 현재의 경향을 표현하는 데 더 적은 영향을 미치게\" 하는 방법이다.\n",
    "\n",
    "### Adam \n",
    "\n",
    "$$ \\text{Momentum : }m_t = \\beta_1m_{t=1} + (1 - \\beta_1)g_t $$\n",
    "\n",
    "\n",
    "$$\\text{EMA of gradient squares : } v_t = \\beta_2v_{t-1} + (1 - \\beta_2)g^2_t$$\n",
    "\n",
    "$$ W_{t+1} = W_t - \\frac{\\eta}{\\sqrt{v_t + \\epsilon}}\\frac{\\sqrt{1 - \\beta^t_2}}{1 - \\beta^t_1} m_t $$\n",
    "\n",
    "- Adam역 Adagrad, Adadelta, RMSprop 처럼 parameter마다 다른 크기로 업데이트한다.\n",
    "가장 잘되고 무난하다. gradient의 크기 변화를 반영하고 이전의 momentum 까지 합친다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5918010",
   "metadata": {},
   "source": [
    "___\n",
    "## Regularization\n",
    "\n",
    "\n",
    "Generalization을 잘되게 하기 위해 규제를 거는 것을 의미한다.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b37146",
   "metadata": {},
   "source": [
    "### Early Stopping\n",
    "\n",
    "- 말 그대로 학습을 멈추는 것. \n",
    "\n",
    "\n",
    "- Test data를 사용하는 것은 치팅 이므로 Validation data를 사용하여 모델 성능을 평가하면서 loss가 커지는 시점에 멈춘다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b73753e",
   "metadata": {},
   "source": [
    "### Parameter norm penalty \n",
    "\n",
    "$$ \\text{total cost} = loss(D;W) + \\frac{\\alpha}{2}||W||^2_2$$\n",
    "\n",
    "- it adds smoothness to the function space. \n",
    "\n",
    "\n",
    "- parameter가 너무 커지지않도록 하는것. network parameter들을 모두 더해 제곱한다음 줄인다.\n",
    "\n",
    "\n",
    "- function space(함수 공간) 속에서 부드러운 함수일수록 Generalization이 잘될것이라는 가정을 전제로 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e858cd",
   "metadata": {},
   "source": [
    "### Data Augmentation\n",
    "\n",
    "- More data are always welcomed. However, in most cases, training data are given in advance. In such cases, we need data augmentation. $\\rightarrow$ Data는 무한히 많을 수록 잘된다\n",
    "\n",
    "\n",
    "- Data를 만들어 낼수는 없으므로 이미 있는 Data를 활용한다. (ex. 강아지 사진을 뒤집거나 좌우반전) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026d4a98",
   "metadata": {},
   "source": [
    "### Noise Robustness\n",
    "\n",
    "- Add random noises inputs or weights. \n",
    "\n",
    "- Data에 의도적으로 noise를 집어 넣으면 더 잘된다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c458a9",
   "metadata": {},
   "source": [
    "### Label smoothing\n",
    "\n",
    "- Mix-up or CutMix constructs augmented training examples by mixing inputs with cut and paste and outputs with soft labels of two randomly selected training data. \n",
    "\n",
    "- Data Augmentation과 비슷하다. 데이터 2개를 뽑아 Mix한다. (강아지와 고양이 이미지를 붙인다.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080dc456",
   "metadata": {},
   "source": [
    "### Dropout\n",
    "\n",
    "- In each forward pass, randomly set some neurons to zero. \n",
    "\n",
    "\n",
    "- 랜덤으로 뉴런들을 0으로 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7ac01c1",
   "metadata": {},
   "source": [
    "### Batch Normalization \n",
    "\n",
    "$$ \\mu\\beta = \\frac{1}{m}\\displaystyle\\sum^m_{i=1} x_i $$\n",
    "\n",
    "\n",
    "$$ \\sigma^2_{\\beta} = \\frac{1}{m} \\displaystyle\\sum^m_{i=1}(x_i - \\mu\\beta)^2$$\n",
    "\n",
    "\n",
    "$$ \\hat x_i = \\frac{x_i - \\mu\\beta}{\\sqrt{\\sigma^2_\\beta + \\epsilon}} $$\n",
    "\n",
    "\n",
    "- Gradient 너무 작거나(Vanishing) 커진다면(Exploding) 신경망을 효과적으로 학습시키지 못하고, Error rate 가 낮아지지 않고 수렴해버리는 문제가 발생한다.\n",
    "\n",
    "\n",
    "- Batch Normalization 논문은 이 원인을 **'Internal Covariance Shift'** 라고 주장한다.\n",
    "    1. Internal Covariance Shift : 네트워크의 각 레이어나 Activation 마다 입력값의 분산이 달라지는 현상\n",
    "    2. Covariate Shift : 이전 레이어의 파라미터 변화로 인하여 현재 레이어의 입력의 분포가 바뀌는 현상 \n",
    "    3.  즉 레이어를 통과할 때 마다 Covariate Shift 가 일어나면서 입력의 분포가 약간씩 달라진다\n",
    "\n",
    "\n",
    "- Batch Normalization은 각 **layer 마다 Normalization** 하여, Covariate Shift가 발생하지 않게 조절하게 한다.\n",
    "\n",
    "\n",
    "- 'Internal Covariance Shift'에 대해선 논란이 많지만 Batch Normalization를 사용하면 학습이 잘된다.\n",
    "\n",
    "\n",
    "\n",
    "- Batch Norm, Layer Norm, Instance Norm, Group Norm 등을 취사선택해보면 좋은 결과가 나온다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e480b01d",
   "metadata": {},
   "source": [
    "Further Reading\n",
    "- [올바르게(?) cross-validation을 하기 위해서는 어떻 방법들이 존재할까요?, Time series의 경우 일반적인 k-fold cv를 사용해도 될까요?]((https://towardsdatascience.com/time-series-nested-cross-validation-76adba623eb9))\n",
    "\n",
    "Further Questions\n",
    "- [RAdam](https://github.com/LiyuanLucasLiu/RAdam)\n",
    "- [AdamP](https://github.com/clovaai/AdamP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555fd979",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
