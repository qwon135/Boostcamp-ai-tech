{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d5feb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "586f2ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14be9eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_games():\n",
    "    for episode in range(10):\n",
    "        env.reset()\n",
    "        for t in range(500):\n",
    "\n",
    "            # display를 해주는 역할\n",
    "            env.render()\n",
    "            \n",
    "            # action을 정해줌(0은 왼쪽 1은 오른쪽)\n",
    "            action = env.action_space.sample()\n",
    "            \n",
    "            # action에 따라 실행하고 관찰된 환경을 return 해줌\n",
    "            next_state, reward, done, info = env.step(action)\n",
    "            \n",
    "            print(f'''t : {episode}-{t}\\nnext_state : {next_state}\\nreward : {reward}\\ndone : {done}\\ninfo : {info}\\naction : {action}''')\n",
    "            print()\n",
    "            if done:\n",
    "                break                        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe208bf",
   "metadata": {},
   "source": [
    "### 에피소드 종료\n",
    "에피소드는 다음 중 하나로 종료된다\n",
    "1. 각도가 ±12° 이상\n",
    "2. 카트 위치가 ±2.4 이상(카트 중앙이 디스플레이 가장자리에 도달)\n",
    "3. episode length가 500보다 큼(v0의 경우 200).\n",
    "\n",
    "### 각 항목들의 의미(공식문서)  \n",
    "\n",
    "#### next_state\n",
    " l, r, t, b : 좌 우 상 하 좌표를 의미\n",
    "\n",
    "#### reward\n",
    "매 step 마다 1의 보상\n",
    "\n",
    "#### done\n",
    "종료조건을 만족하여 gameover를 의미\n",
    "\n",
    "`done = bool(`  \n",
    "`            x < -self.x_threshold`  \n",
    "`            or x > self.x_threshold`  \n",
    "`            or theta < -self.theta_threshold_radians`  \n",
    "`            or theta > self.theta_threshold_radians`  \n",
    "`        )`  \n",
    "\n",
    "#### action\n",
    "1은 cart를 오른쪽으로, 0은 왼쪽으로 움직임을 의미\n",
    "\n",
    "    | Num | Action                 |\n",
    "    |-----|------------------------|\n",
    "    | 0   | Push cart to the left  |\n",
    "    | 1   | Push cart to the right |\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6e3f62c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t : 0-0\n",
      "next_state : [ 0.02741178  0.16979925 -0.01789352 -0.34326407]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 0-1\n",
      "next_state : [ 0.03080776  0.36517113 -0.0247588  -0.6415354 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 0-2\n",
      "next_state : [ 0.03811118  0.17040291 -0.03758951 -0.35675094]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 0-3\n",
      "next_state : [ 0.04151924 -0.02416501 -0.04472453 -0.07615392]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 0-4\n",
      "next_state : [ 0.04103594  0.17156862 -0.04624761 -0.3826054 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 0-5\n",
      "next_state : [ 0.04446732  0.36731568 -0.05389972 -0.68950397]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 0-6\n",
      "next_state : [ 0.05181363  0.56314254 -0.06768979 -0.9986566 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 0-7\n",
      "next_state : [ 0.06307648  0.3689876  -0.08766293 -0.7279767 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 0-8\n",
      "next_state : [ 0.07045623  0.565205   -0.10222246 -1.0469126 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 0-9\n",
      "next_state : [ 0.08176033  0.7615241  -0.12316071 -1.369855  ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 0-10\n",
      "next_state : [ 0.09699081  0.95795274 -0.15055782 -1.6983839 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 0-11\n",
      "next_state : [ 0.11614987  0.7648533  -0.18452549 -1.4561083 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 0-12\n",
      "next_state : [ 0.13144693  0.57241255 -0.21364765 -1.2262908 ]\n",
      "reward : 1.0\n",
      "done : True\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 1-0\n",
      "next_state : [ 0.00382291  0.21496817  0.00057587 -0.27323228]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 1-1\n",
      "next_state : [ 0.00812227  0.019838   -0.00488878  0.01963223]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 1-2\n",
      "next_state : [ 0.00851903  0.21502972 -0.00449613 -0.27458915]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 1-3\n",
      "next_state : [ 0.01281962  0.01997221 -0.00998791  0.01667231]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 1-4\n",
      "next_state : [ 0.01321907 -0.1750051  -0.00965447  0.30618727]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 1-5\n",
      "next_state : [ 0.00971897  0.0202531  -0.00353072  0.01047527]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 1-6\n",
      "next_state : [ 0.01012403  0.2154255  -0.00332122 -0.28331956]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 1-7\n",
      "next_state : [ 0.01443254  0.02035108 -0.00898761  0.00831404]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 1-8\n",
      "next_state : [ 0.01483956 -0.17464083 -0.00882133  0.29814777]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 1-9\n",
      "next_state : [ 0.01134674  0.02060575 -0.00285837  0.00269586]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 1-10\n",
      "next_state : [ 0.01175886 -0.17447509 -0.00280445  0.29447556]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 1-11\n",
      "next_state : [0.00826936 0.02068673 0.00308506 0.00090948]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 1-12\n",
      "next_state : [ 0.00868309  0.2157643   0.00310325 -0.2907985 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 1-13\n",
      "next_state : [ 0.01299838  0.02059824 -0.00271272  0.00286155]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 1-14\n",
      "next_state : [ 0.01341034 -0.1744847  -0.00265549  0.29468736]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 1-15\n",
      "next_state : [0.00992065 0.02067501 0.00323825 0.00116811]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 1-16\n",
      "next_state : [ 0.01033415  0.21575037  0.00326162 -0.29049134]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 1-17\n",
      "next_state : [ 0.01464915  0.41082567 -0.00254821 -0.58214384]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 1-18\n",
      "next_state : [ 0.02286567  0.2157395  -0.01419109 -0.29026473]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 1-19\n",
      "next_state : [ 0.02718046  0.4110609  -0.01999638 -0.58738935]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 1-20\n",
      "next_state : [ 0.03540168  0.21622463 -0.03174417 -0.3010719 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 1-21\n",
      "next_state : [ 0.03972617  0.02156916 -0.03776561 -0.01856703]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 1-22\n",
      "next_state : [ 0.04015755 -0.17299141 -0.03813695  0.26196527]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 1-23\n",
      "next_state : [ 0.03669772 -0.3675488  -0.03289764  0.5423796 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 1-24\n",
      "next_state : [ 0.02934675 -0.56219333 -0.02205005  0.82451826]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 1-25\n",
      "next_state : [ 0.01810288 -0.36677682 -0.00555968  0.5249826 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 1-26\n",
      "next_state : [ 0.01076734 -0.5618201   0.00493997  0.81590843]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 1-27\n",
      "next_state : [-4.6905727e-04 -7.5700933e-01  2.1258138e-02  1.1101410e+00]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 1-28\n",
      "next_state : [-0.01560924 -0.56217307  0.04346096  0.8242021 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 1-29\n",
      "next_state : [-0.0268527 -0.7578617  0.059945   1.1302314]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 1-30\n",
      "next_state : [-0.04200994 -0.9537152   0.08254963  1.4410973 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 1-31\n",
      "next_state : [-0.06108424 -1.1497511   0.11137157  1.7583917 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 1-32\n",
      "next_state : [-0.08407927 -1.3459445   0.1465394   2.0835342 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 1-33\n",
      "next_state : [-0.11099815 -1.1525774   0.18821009  1.8395208 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 1-34\n",
      "next_state : [-0.1340497 -1.349214   0.2250005  2.1842747]\n",
      "reward : 1.0\n",
      "done : True\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 2-0\n",
      "next_state : [ 0.03157606  0.16985354 -0.01316226 -0.34544656]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 2-1\n",
      "next_state : [ 0.03497313  0.36516023 -0.02007119 -0.6422508 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 2-2\n",
      "next_state : [ 0.04227634  0.17032371 -0.03291621 -0.35595542]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 2-3\n",
      "next_state : [ 0.04568281 -0.02431516 -0.04003532 -0.0738309 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 2-4\n",
      "next_state : [ 0.04519651  0.1713572  -0.04151193 -0.37887147]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 2-5\n",
      "next_state : [ 0.04862365 -0.0231514  -0.04908936 -0.09956094]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 2-6\n",
      "next_state : [ 0.04816062 -0.21753669 -0.05108058  0.17723928]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 2-7\n",
      "next_state : [ 0.04380989 -0.41189185 -0.0475358   0.45338058]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 2-8\n",
      "next_state : [ 0.03557206 -0.6063105  -0.03846819  0.7307089 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 2-9\n",
      "next_state : [ 0.02344584 -0.80088025 -0.02385401  1.0110408 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 2-10\n",
      "next_state : [ 0.00742824 -0.9956759  -0.00363319  1.2961388 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 2-11\n",
      "next_state : [-0.01248528 -1.1907516   0.02228958  1.587682  ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 2-12\n",
      "next_state : [-0.03630031 -1.3861312   0.05404322  1.8872312 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 2-13\n",
      "next_state : [-0.06402294 -1.5817971   0.09178784  2.1961827 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 2-14\n",
      "next_state : [-0.09565888 -1.3876722   0.1357115   1.9331689 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 2-15\n",
      "next_state : [-0.12341232 -1.5839605   0.17437488  2.2646708 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 2-16\n",
      "next_state : [-0.15509152 -1.7802324   0.2196683   2.605621  ]\n",
      "reward : 1.0\n",
      "done : True\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 3-0\n",
      "next_state : [-0.01925825  0.16849287  0.04398951 -0.22978115]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 3-1\n",
      "next_state : [-0.01588839  0.3629595   0.03939389 -0.50827014]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 3-2\n",
      "next_state : [-0.0086292   0.1673053   0.02922848 -0.20343776]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 3-3\n",
      "next_state : [-0.0052831   0.36199734  0.02515973 -0.4867591 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 3-4\n",
      "next_state : [ 0.00195685  0.5567554   0.01542455 -0.7714076 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 3-5\n",
      "next_state : [ 1.3091956e-02  7.5166172e-01 -3.6039285e-06 -1.0591977e+00]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 3-6\n",
      "next_state : [ 0.02812519  0.55653983 -0.02118756 -0.76651585]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 3-7\n",
      "next_state : [ 0.03925599  0.3617159  -0.03651787 -0.48057425]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 3-8\n",
      "next_state : [ 0.0464903   0.5573338  -0.04612936 -0.78453934]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 3-9\n",
      "next_state : [ 0.05763698  0.75305825 -0.06182015 -1.0913709 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 3-10\n",
      "next_state : [ 0.07269815  0.5588031  -0.08364756 -0.8187083 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 3-11\n",
      "next_state : [ 0.08387421  0.36491957 -0.10002173 -0.55346364]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t : 3-12\n",
      "next_state : [ 0.0911726  0.5612933 -0.111091  -0.8759094]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 3-13\n",
      "next_state : [ 0.10239846  0.3678425  -0.1286092  -0.6201155 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 3-14\n",
      "next_state : [ 0.10975531  0.5645038  -0.1410115  -0.9503781 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 3-15\n",
      "next_state : [ 0.12104539  0.3715325  -0.16001907 -0.7051144 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 3-16\n",
      "next_state : [ 0.12847604  0.56846726 -0.17412135 -1.0435877 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 3-17\n",
      "next_state : [ 0.13984539  0.7654196  -0.19499311 -1.3854824 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 3-18\n",
      "next_state : [ 0.15515378  0.573189   -0.22270276 -1.1595663 ]\n",
      "reward : 1.0\n",
      "done : True\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 4-0\n",
      "next_state : [-0.0444962  -0.16960007 -0.03689789  0.23838653]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 4-1\n",
      "next_state : [-0.0478882   0.02602905 -0.03213016 -0.06570293]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 4-2\n",
      "next_state : [-0.04736762 -0.16861786 -0.03344422  0.21667211]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 4-3\n",
      "next_state : [-0.05073998 -0.36324614 -0.02911077  0.49862048]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 4-4\n",
      "next_state : [-0.0580049  -0.55794585 -0.01913836  0.7819889 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 4-5\n",
      "next_state : [-0.06916381 -0.3625661  -0.00349859  0.4833467 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 4-6\n",
      "next_state : [-0.07641514 -0.5576385   0.00616835  0.77492493]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 4-7\n",
      "next_state : [-0.08756791 -0.75284475  0.02166685  1.0695422 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 4-8\n",
      "next_state : [-0.1026248  -0.558016    0.04305769  0.7837372 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 4-9\n",
      "next_state : [-0.11378513 -0.36351135  0.05873244  0.5049057 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 4-10\n",
      "next_state : [-0.12105535 -0.5594097   0.06883055  0.81550395]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 4-11\n",
      "next_state : [-0.13224354 -0.75540316  0.08514063  1.1290183 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 4-12\n",
      "next_state : [-0.14735161 -0.5614932   0.10772099  0.86420804]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 4-13\n",
      "next_state : [-0.15858148 -0.36798957  0.12500516  0.6072437 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 4-14\n",
      "next_state : [-0.16594127 -0.56461716  0.13715003  0.93653953]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 4-15\n",
      "next_state : [-0.1772336  -0.3715846   0.15588082  0.68990546]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 4-16\n",
      "next_state : [-0.18466529 -0.17892982  0.16967893  0.45007077]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 4-17\n",
      "next_state : [-0.1882439  -0.37599424  0.17868035  0.7910689 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 4-18\n",
      "next_state : [-0.19576378 -0.18371654  0.19450173  0.5594972 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 4-19\n",
      "next_state : [-0.19943811  0.00822019  0.20569167  0.33384442]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 4-20\n",
      "next_state : [-0.1992737  -0.18914454  0.21236855  0.68369865]\n",
      "reward : 1.0\n",
      "done : True\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 5-0\n",
      "next_state : [-0.02860169  0.16056126  0.05002021 -0.25188377]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 5-1\n",
      "next_state : [-0.02539046 -0.03523794  0.04498254  0.0561475 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 5-2\n",
      "next_state : [-0.02609522  0.15921114  0.04610549 -0.22201066]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 5-3\n",
      "next_state : [-0.022911   -0.03653846  0.04166527  0.08485191]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 5-4\n",
      "next_state : [-0.02364177  0.15796225  0.04336232 -0.1943999 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 5-5\n",
      "next_state : [-0.02048252 -0.0377523   0.03947432  0.1116405 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 5-6\n",
      "next_state : [-0.02123757  0.15678243  0.04170713 -0.16833185]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 5-7\n",
      "next_state : [-0.01810192  0.35128334  0.03834049 -0.44757116]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 5-8\n",
      "next_state : [-0.01107625  0.1556406   0.02938907 -0.14305337]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 5-9\n",
      "next_state : [-0.00796344  0.3503296   0.026528   -0.42632163]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 5-10\n",
      "next_state : [-0.00095685  0.54506594  0.01800157 -0.71052504]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 5-11\n",
      "next_state : [ 0.00994447  0.34969938  0.00379106 -0.41223052]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 5-12\n",
      "next_state : [ 0.01693846  0.15452391 -0.00445355 -0.11835483]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 5-13\n",
      "next_state : [ 0.02002894  0.3497094  -0.00682064 -0.41243947]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 5-14\n",
      "next_state : [ 0.02702312  0.54492736 -0.01506943 -0.7072649 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 5-15\n",
      "next_state : [ 0.03792167  0.35001737 -0.02921473 -0.41936335]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 5-16\n",
      "next_state : [ 0.04492202  0.54554087 -0.037602   -0.7211113 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 5-17\n",
      "next_state : [ 0.05583283  0.3509587  -0.05202422 -0.4404968 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 5-18\n",
      "next_state : [ 0.06285201  0.54677683 -0.06083416 -0.7491148 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 5-19\n",
      "next_state : [ 0.07378755  0.7426828  -0.07581645 -1.0603044 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 5-20\n",
      "next_state : [ 0.0886412   0.5486424  -0.09702254 -0.79234856]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 5-21\n",
      "next_state : [ 0.09961405  0.3549768  -0.11286952 -0.5316963 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 5-22\n",
      "next_state : [ 0.10671359  0.5514903  -0.12350344 -0.85770416]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 5-23\n",
      "next_state : [ 0.11774339  0.35824776 -0.14065753 -0.606266  ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 5-24\n",
      "next_state : [ 0.12490834  0.5550272  -0.15278284 -0.93973714]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 5-25\n",
      "next_state : [ 0.13600889  0.75184166 -0.17157759 -1.2762635 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 5-26\n",
      "next_state : [ 0.15104572  0.5592718  -0.19710286 -1.0418468 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 5-27\n",
      "next_state : [ 0.16223116  0.36723542 -0.2179398  -0.8169433 ]\n",
      "reward : 1.0\n",
      "done : True\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 6-0\n",
      "next_state : [ 0.01130251  0.20375144  0.04879898 -0.32212052]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 6-1\n",
      "next_state : [ 0.01537754  0.00796978  0.04235657 -0.0144564 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 6-2\n",
      "next_state : [ 0.01553693  0.20245948  0.04206744 -0.29348022]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 6-3\n",
      "next_state : [0.01958612 0.0067638  0.03619783 0.0121678 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 6-4\n",
      "next_state : [ 0.0197214  -0.18885808  0.03644119  0.31604823]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 6-5\n",
      "next_state : [0.01594424 0.00572637 0.04276216 0.03507669]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 6-6\n",
      "next_state : [ 0.01605877  0.20020984  0.04346369 -0.24381359]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 6-7\n",
      "next_state : [0.02006296 0.0044949  0.03858742 0.06225587]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 6-8\n",
      "next_state : [ 0.02015286 -0.19115844  0.03983254  0.36685932]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 6-9\n",
      "next_state : [ 0.01632969 -0.38682312  0.04716972  0.6718312 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 6-10\n",
      "next_state : [ 0.00859323 -0.19238752  0.06060635  0.39436495]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 6-11\n",
      "next_state : [ 0.00474548 -0.38831475  0.06849364  0.70552355]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 6-12\n",
      "next_state : [-0.00302082 -0.58431554  0.08260412  1.0189568 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 6-13\n",
      "next_state : [-0.01470713 -0.39038587  0.10298325  0.7533122 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 6-14\n",
      "next_state : [-0.02251484 -0.1968232   0.11804949  0.49473   ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 6-15\n",
      "next_state : [-0.02645131 -0.39339483  0.1279441   0.8221613 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 6-16\n",
      "next_state : [-0.0343192  -0.20023377  0.14438732  0.57230103]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 6-17\n",
      "next_state : [-0.03832388 -0.00740003  0.15583333  0.3283628 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 6-18\n",
      "next_state : [-0.03847188 -0.20435739  0.16240059  0.6658487 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 6-19\n",
      "next_state : [-0.04255903 -0.01182212  0.17571756  0.42838204]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 6-20\n",
      "next_state : [-0.04279547  0.18043272  0.18428521  0.19583598]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 6-21\n",
      "next_state : [-0.03918682 -0.01678131  0.18820193  0.54052174]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t : 6-22\n",
      "next_state : [-0.03952244  0.17526628  0.19901237  0.31254235]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 6-23\n",
      "next_state : [-0.03601712 -0.02205187  0.20526321  0.6608019 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 6-24\n",
      "next_state : [-0.03645815  0.1697122   0.21847925  0.4391187 ]\n",
      "reward : 1.0\n",
      "done : True\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 7-0\n",
      "next_state : [ 0.00105308  0.1542101  -0.00138507 -0.32871974]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 7-1\n",
      "next_state : [ 0.00413728 -0.0408921  -0.00795947 -0.03647393]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 7-2\n",
      "next_state : [ 0.00331944  0.15434308 -0.00868895 -0.33165747]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 7-3\n",
      "next_state : [ 0.0064063  -0.04065412 -0.01532209 -0.04172724]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 7-4\n",
      "next_state : [ 0.00559322 -0.23555304 -0.01615664  0.2460823 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 7-5\n",
      "next_state : [ 0.00088216 -0.43044055 -0.01123499  0.5336256 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 7-6\n",
      "next_state : [-0.00772665 -0.23516242 -0.00056248  0.23742384]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 7-7\n",
      "next_state : [-0.0124299  -0.04003243  0.004186   -0.05543646]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 7-8\n",
      "next_state : [-0.01323055 -0.23521416  0.00307727  0.23856424]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 7-9\n",
      "next_state : [-0.01793483 -0.43037993  0.00784855  0.53221625]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 7-10\n",
      "next_state : [-0.02654243 -0.62561136  0.01849288  0.8273618 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 7-11\n",
      "next_state : [-0.03905466 -0.43074712  0.03504011  0.540552  ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 7-12\n",
      "next_state : [-0.0476696  -0.23613477  0.04585115  0.2591124 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 7-13\n",
      "next_state : [-0.0523923 -0.4318803  0.0510334  0.5658976]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 7-14\n",
      "next_state : [-0.0610299  -0.62767965  0.06235135  0.87421155]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 7-15\n",
      "next_state : [-0.07358349 -0.4334583   0.07983558  0.6017651 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 7-16\n",
      "next_state : [-0.08225266 -0.6296009   0.09187088  0.91848856]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 7-17\n",
      "next_state : [-0.09484468 -0.43583292  0.11024065  0.6560344 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 7-18\n",
      "next_state : [-0.10356133 -0.24240433  0.12336134  0.39999792]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 7-19\n",
      "next_state : [-0.10840943 -0.4390405   0.1313613   0.7288871 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 7-20\n",
      "next_state : [-0.11719023 -0.63571     0.14593904  1.0598589 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 7-21\n",
      "next_state : [-0.12990443 -0.83243155  0.16713622  1.3945584 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 7-22\n",
      "next_state : [-0.14655307 -1.029192    0.1950274   1.734496  ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 7-23\n",
      "next_state : [-0.16713691 -0.83675665  0.22971731  1.5082904 ]\n",
      "reward : 1.0\n",
      "done : True\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 8-0\n",
      "next_state : [ 0.03751091  0.23247339 -0.01044101 -0.2574531 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 8-1\n",
      "next_state : [ 0.04216038  0.42774284 -0.01559007 -0.5534109 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 8-2\n",
      "next_state : [ 0.05071524  0.23284324 -0.02665829 -0.26568034]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 8-3\n",
      "next_state : [ 0.0553721   0.42833534 -0.03197189 -0.56665087]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 8-4\n",
      "next_state : [ 0.06393881  0.23367614 -0.04330491 -0.28420946]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 8-5\n",
      "next_state : [ 0.06861233  0.4293881  -0.0489891  -0.59022987]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 8-6\n",
      "next_state : [ 0.07720009  0.6251605  -0.0607937  -0.8979332 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 8-7\n",
      "next_state : [ 0.08970331  0.8210515  -0.07875236 -1.2090892 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 8-8\n",
      "next_state : [ 0.10612433  1.0170972  -0.10293414 -1.5253756 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 8-9\n",
      "next_state : [ 0.12646627  1.2133001  -0.13344166 -1.8483315 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 8-10\n",
      "next_state : [ 0.15073228  1.4096155  -0.17040828 -2.1793022 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 8-11\n",
      "next_state : [ 0.17892459  1.6059355  -0.21399432 -2.5193746 ]\n",
      "reward : 1.0\n",
      "done : True\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 9-0\n",
      "next_state : [-0.02097924 -0.15274732  0.02724896  0.32826635]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 9-1\n",
      "next_state : [-0.02403419  0.04197633  0.03381429  0.04429954]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 9-2\n",
      "next_state : [-0.02319466  0.2365975   0.03470028 -0.23752582]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 9-3\n",
      "next_state : [-0.01846271  0.43120697  0.02994976 -0.5190644 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 9-4\n",
      "next_state : [-0.00983857  0.23567644  0.01956847 -0.2170963 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 9-5\n",
      "next_state : [-0.00512504  0.43051326  0.01522655 -0.50354284]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 9-6\n",
      "next_state : [ 0.00348522  0.62541735  0.00515569 -0.7913886 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 9-7\n",
      "next_state : [ 0.01599357  0.43022498 -0.01067208 -0.4970882 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 9-8\n",
      "next_state : [ 0.02459807  0.23525512 -0.02061384 -0.20778759]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 9-9\n",
      "next_state : [ 0.02930317  0.04043391 -0.02476959  0.07832211]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 9-10\n",
      "next_state : [ 0.03011185  0.23590203 -0.02320315 -0.22207165]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 9-11\n",
      "next_state : [ 0.03482989  0.04111928 -0.02764459  0.06320272]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 9-12\n",
      "next_state : [ 0.03565228  0.23662646 -0.02638053 -0.23807247]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 9-13\n",
      "next_state : [ 0.04038481  0.43211517 -0.03114198 -0.5389585 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 9-14\n",
      "next_state : [ 0.04902711  0.62766075 -0.04192115 -0.84128886]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 9-15\n",
      "next_state : [ 0.06158032  0.43313536 -0.05874693 -0.56207836]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 9-16\n",
      "next_state : [ 0.07024303  0.2388849  -0.0699885  -0.288467  ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 9-17\n",
      "next_state : [ 0.07502073  0.04482716 -0.07575783 -0.01865286]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 9-18\n",
      "next_state : [ 0.07591727 -0.1491312  -0.07613089  0.24919869]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 9-19\n",
      "next_state : [ 0.07293465  0.04699075 -0.07114692 -0.06649297]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 9-20\n",
      "next_state : [ 0.07387447 -0.14704284 -0.07247677  0.20292155]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 9-21\n",
      "next_state : [ 0.0709336  -0.34105748 -0.06841835  0.47188997]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 9-22\n",
      "next_state : [ 0.06411245 -0.14503926 -0.05898055  0.15845123]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 9-23\n",
      "next_state : [ 0.06121167  0.05087535 -0.05581152 -0.1522399 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 9-24\n",
      "next_state : [ 0.06222918  0.24675019 -0.05885632 -0.46199477]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 9-25\n",
      "next_state : [ 0.06716418  0.05250731 -0.06809621 -0.18842871]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 9-26\n",
      "next_state : [ 0.06821433  0.24853408 -0.07186479 -0.5017922 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 9-27\n",
      "next_state : [ 0.07318501  0.05449479 -0.08190063 -0.23259461]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 9-28\n",
      "next_state : [ 0.07427491  0.2506857  -0.08655252 -0.54994637]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 9-29\n",
      "next_state : [ 0.07928862  0.05687929 -0.09755146 -0.2857397 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 9-30\n",
      "next_state : [ 0.08042621  0.25324735 -0.10326625 -0.60752606]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 9-31\n",
      "next_state : [ 0.08549115  0.05970925 -0.11541677 -0.34907177]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 9-32\n",
      "next_state : [ 0.08668534  0.25626734 -0.12239821 -0.67580456]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 9-33\n",
      "next_state : [ 0.09181069  0.45285836 -0.1359143  -1.0043802 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 9-34\n",
      "next_state : [ 0.10086785  0.64950806 -0.1560019  -1.3364704 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 1\n",
      "\n",
      "t : 9-35\n",
      "next_state : [ 0.11385801  0.4566572  -0.18273132 -1.0963857 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t : 9-36\n",
      "next_state : [ 0.12299116  0.26434946 -0.20465903 -0.8661512 ]\n",
      "reward : 1.0\n",
      "done : False\n",
      "info : {}\n",
      "action : 0\n",
      "\n",
      "t : 9-37\n",
      "next_state : [ 0.12827815  0.46158043 -0.22198205 -1.215574  ]\n",
      "reward : 1.0\n",
      "done : True\n",
      "info : {}\n",
      "action : 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Random_games()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182db6e4",
   "metadata": {},
   "source": [
    "[실제 영상](https://www.youtube.com/watch?v=5Q14EjnOJZc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
