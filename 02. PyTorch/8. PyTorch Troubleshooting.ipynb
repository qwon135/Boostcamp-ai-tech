{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "304b34ad",
   "metadata": {},
   "source": [
    "PyTorch를 사용하면서 문제가 생길 때의 해결법"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6415cf8",
   "metadata": {},
   "source": [
    "공포의 단어 : OOM(out of memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b07a4f",
   "metadata": {},
   "source": [
    "### OOM을 해결하기 어려운 이유\n",
    "- 왜 발생했는지 알기 어려움\n",
    "- 어디서 발생했는지 알기 어려움  \n",
    "    : Python과 다르게 PyTorch는 발생 위치를 말해주지 않는다.\n",
    "- Error backtracking이 이상한데로 감\n",
    "- memory의 이전상황의 파악이 어려움  \n",
    "    : 보통 error는 iteration이 돌아가면서 발생"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221277bf",
   "metadata": {},
   "source": [
    "#### 단순한 해결방법 : Batch Size를 줄이고 GPU를 clean하고 다시 실행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f0ee78",
   "metadata": {},
   "source": [
    "### 그 외 발생할 만한 문제들"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eacbc4c",
   "metadata": {},
   "source": [
    "### GPU Util 사용하기\n",
    "- 현재 GPU의 상태를 정확히 알기 위해 사용한다.\n",
    "- nvidia-smi 처럼 GPU의 상태를 보여주는 모듈\n",
    "- Colab은 환경에서 GPU 상태를 보여주기 편함\n",
    "- iter마다 메모리가 늘어나는지 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5ef093",
   "metadata": {},
   "source": [
    "### torch.cuda.empty_cache() 써보기\n",
    "- 사용되지 않은 GPU상 cache를 정리\n",
    "- 가용 메모리를 확보\n",
    "- del과는 구분이 필요(del은 관계를 끊어버린다)\n",
    "- reset 대신 쓰기 좋은 함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "862fb220",
   "metadata": {},
   "source": [
    "### trainnin loop에 tensor로 축적되는 변수는 확인할 것\n",
    "- tensor로 처리된 변수는 GPU상에 메모리 사용\n",
    "- 해당 변수 loop안에 연산에 있을 때 GPU에 conputational graph를 생성(메모리 잠식)\n",
    "- 1-d tensor의 경우 python 기본 객체로 변환하여 처리할 것\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce450f3",
   "metadata": {},
   "source": [
    "### del 명령어를 적절히 사용하기\n",
    "- 필요가 없어진 변수는 적절한 삭제가 필요\n",
    "- python의 메모리 배치 특성상 loop이 끝나도 메모리를 차지함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d91bb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "for x in range(10):\n",
    "    i = x\n",
    "print(i) # iter가 끝나도 i가 남아 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a943678d",
   "metadata": {},
   "source": [
    "### 가능 batch 사이즈 실험해보기\n",
    "- 학습시 OOM이 발생했다면 batch 사이즈를 1로 해서 실험해보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd548493",
   "metadata": {},
   "source": [
    "### torch.no_grad() 사용하기\n",
    "- Inference 시점에서는 torch.no_grad() 구문을 사용\n",
    "- backward pass 으로 인해 쌓이는 메모리에서 자유로움\n",
    "- 습관적으로 Inference 시점에서는 사용하는게 좋다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659d767e",
   "metadata": {},
   "source": [
    "### 예상치 못한 에러 메시지\n",
    "- OOM 말고도 유사한 에러가 발생\n",
    "- CUDNN_STATUS_NOT_INIT 이나 device-side-assert 등\n",
    "- 해당 에러도 cuda와 관련하여 OOM의 일종이므로, 적절한 코드 처리 필요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a1a989",
   "metadata": {},
   "source": [
    "#### 그외\n",
    "- colab에서는 너무 큰 사이즈는 실행하지말 것(linear, CNN, LSTM)\n",
    "- CNN의 대부분의 에러는 크기가 안맞아서 생김(torchsummary등으로 사이즈를 맞출것)\n",
    "- tensor의 float precision을 16bit로 줄일 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
